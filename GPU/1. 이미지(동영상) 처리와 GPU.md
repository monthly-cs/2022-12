# GPU에 대해서

이 문서는 2022년 12월 14일에 @unchaptered에 의해서 작성되었습니다.

```
1. 서론
  1.1. 이미지 및 영상처리의 시장
  1.2. 더욱 효율적인 이미지 및 영상처리 방법으로써의 CUDA
  1.3. 그래서 CUDA가 무엇인데?
2. 본론
  2.1. GPU란?
  2.2. 모니터로 보는 CPU와 GPU의 차이
3. 참고
```

## 1. 서론

본문의 첫 주제는 **CPU와 GPU의 차이**와 이에 나아가서 **GPU란 무엇인가**였어요. 

주제 선정의 이유는 **최근 GPU기반 개발이 가지고 있는 명확한 이점**이 있기 때문이었죠. <br>
이런 이점은 매우 흥미롭고 **이미지 및 영상 처리**를 하게 되었을 때, 더 멀리 볼 수 있게 된다고 생각해요.

하지만 다소 생소한 내용인 만큼, 제가 해보고 또 주워들은 **다양한 레퍼런스**를 공유한다면 이 주제에 대한 몰입도를 높일 수 있을 것이라 생각했어요. <br>
여기서 언급한 솔루션들은 **많은 수의 레퍼런스와 무료에 가까운 연습 비용**이라는 큰 장점을 가지고 있어요.

일부 물리적인 한계가 있을 수는 있으나 <br>
대다수의 경우, 언젠가 한 번 즈음은 마주할 주제라고 생각해요!

### 1.1. 이미지 및 영상처리의 시장

시각처리 기술은 이미 많은 부분, 개발자들에게 다가와 있어요.

보통 가장 빨리 경험하는 서비스라면 역시 AWS S3 (혹은 multer)가 아닐까 싶어요. <br>
AWS에서 2006년에 선보인 S3는 이미지의 저장 및 공급에 대한 수많은 솔루션을 가지고 있고 이들은 다양한 문제를 해결해주고 <br>

특히,<br>
Cloudfront(+Edge Location), KMS(CMK)등으로 사용자의 멀티 미디어 파일을 **비용 및 성능 효율적**으로 그리고 **안정적**으로 공급할 수 있어요.

> 1. S3 버킷에 이미지를 업로드하고 다운로드 할 수 있다.
> 2. S3 버킷에 이미지를 Cloudfront에 캐싱을 통해서 빠르고 효율적으로 공급할 수 있다.
> 3. S3 버킷의 이미지를 암호화하고 복호화할 수 있다.
> 4. S3 버킷의 이미지를 제한된 시간만 제한된 사용자에게 공급할 수 있다.
> 5. Cloudfront + Live Streaming을 이용해서 실시간 동영상 소통을 할 수 있다.
> 6. S3 HLS Video를 통해서 단방향 실시간 소통을 할 수 있다.

또한, (제한된) 무료오픈소스 라이브러리인 ffmpeg은 직접적으로 이미지에 대한 다양한 처리를 할 수 있었요.

> 1. ffmpeg로 이미지 및 동영상의 화질을 변경할 수 있다.
> 2. ffmpeg으로 이미지 및 동영상의 코덱을 H264 및 HLS 등으로 변경할 수 있다.
> 3. ffmpeg으로 이미지 및 동영상에 워터마크 등을 넣을 수 있다.
> 4. ffmpeg으로 이미지 및 동영상에 자체 암호화 처리를 하고 이를 통해 DRM으로 구현할 수 있다.

이 중에서도 DRM은 간단한 구글링 만으로도 사용 사례를 찾아볼 수 있습니다.

<img
     style="width: 500px;"
     src="https://user-images.githubusercontent.com/86306802/207588526-b92dd824-400e-4502-99da-9cd44d19c952.png" />

이렇게 이미지 및 영상처리와 관련된 수많은 솔루션이 제공되어 있으며, 이를 통해서 ***더 좋고 안전한 서비스***를 만드는 것이 가능하네요.

그렇다면 여기에서 끝일까요?
OpenCV, Object Detection, MediaPipe와 같이 인공지능 및 머신러닝 분야에서 쓰이는 수많은 오픈 소스의 성능은 소름끼칠 정도로 높아졌으며, 간단한 프로젝트에서는 누구나 쉽게 이러한 서비스를 개발해보는 경험을 쌓을 수 있어요.

이번 주제는 이러한 **이미지 처리(후가공) 분야**에서 사용할 수 있을 주제라고 생각합니다.

### 1.2. 더욱 효율적인 이미지 및 영상처리 방법으로써의 CUDA

가장 빠른 길은 **좋은 컴퓨터를 사는 것**이 있습니다. <br>
그 다음은 **좋은 라이브러리를 사는 것(혹은 찾는 것)**도 있습니다.

예를 들어, CPU를 이용해서 동영상 코덱을 변환하기 위해서 ffmpeg를 쓰고 있다고 생각해봅시다. <br>
1번, 2번에서 더이상 개선사항을 찾기 어려운 순간이 왔을 때, ffmpeg의 성능을 끌어올리는 방법은 없을까요?

그 정답은 [NVIDIA - Using FFmpeg with NVIDIA GPU Hardware Acceleration](https://docs.nvidia.com/video-technologies/video-codec-sdk/ffmpeg-with-nvidia-gpu/)와 같은 라이브러리가 제공해줍니다.

### 1.3. 그래서 CUDA가 무엇인데?

CUDA라는 것은 NVIDIA에 개발한 **GPU 개발 라이브러리**에요.

후술하겠지만, CUDA를 나타내는 가장 큰 특징은 **병렬 프로그래밍**이라고 할 수 있을 것 같아요.

제품 소개에 대한 더 자세한 내용은 [NVIDIA - What is CUDA?](https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/)을 참고해주세요.

## 2. 본론

### 2.1. GPU란?

NIVIDA에서는 [NVIDIA의 과학시간 - GPU와 CPU의 차이](https://youtu.be/1BAZf3PsjWA)를 통해서 두 로보트를 선보입니다.

1. 직렬 연산처리를 진행하며 오버클럭을 통해서 성능을 끌어올리는 **레오나르도(1.0)** (0:44)
2. 병렬 연산처리를 진행하며 낮은 성능의 칩이 수없이 연결되어 있는 **레오나르도(2.0)** (2:24)

<img 
     style="width: 600px;"
     src="https://user-images.githubusercontent.com/86306802/207593965-b1a71394-8e90-46ab-8648-603d43559f59.png"/>

### 2.2. 모니터로 보는 CPU와 GPU의 차이

이번에는 개발자 라라의 [개발자 라라 - CPU와 GPU의 차이점](https://youtu.be/taMH5Dickv4)를 통해서 모니터의 예시를 보도록 할게요.

<img 
     style="width: 600px;"
     src="https://user-images.githubusercontent.com/86306802/207595052-c2ee7408-c04a-44aa-87a5-83968fba443f.png"/>

위와 같은 모니터를 그리기 위해서 컴퓨터는 총 1억 2441만 6천번 (124,416,000)의 연산을 진행해야 합니다.

이 작업을 CPU 와 GPU가 처리하게 될 경우, 다음과 같은 시나리오가 발생할 수 있습니다.

<img 
     style="width: 600px;"
     src="https://user-images.githubusercontent.com/86306802/207596134-cb83b86d-fef7-443b-acb6-44caf2e6f43e.png"/>

대다수의 시각화 처리는 **연산의 크기보다 수가 더 많은 특징**을 가지고 있습니다.<br>
따라서 고속 연산 기반의 직렬 연산처리 프로세서인 CPU보다는 조금 느리지만 병렬 처리인 GPU가 훨씬 적합합니다.

![image](https://user-images.githubusercontent.com/86306802/207596774-e8cc953c-fa02-4aa2-9284-7dbd4aa9dedb.png

| CPU | GPU |
| --- | --- |
| Central Processing Unit | Graphics Processing Unit |
| Low Latency | High Throughput |
| Good for serial processing | Good for parallel processing |
| Can do a handful of operations at once | Can do thousands of operations at once |

### 2.3. 진짜 빨라요?

GPU는 행렬 백터 연산에 탁월한 성능을 가지고 있는 만큼, 표본 1개의 크기가 클수록 더 빛을 발하게 됩니다.
다음과 같이 GPU 프로그래밍 라이브러리인 CUDA 예제, [cherry servers - What is GPU Programming?](https://www.cherryservers.com/blog/introduction-to-gpu-programming-with-cuda-and-python#what-is-gpu-programming)에서는 다음과 같이 벤치마킹 결과를 제공해주고 있습니다.

![image](https://user-images.githubusercontent.com/86306802/207601878-269a60ad-a004-48b7-a92a-ed1f6ee1634a.png)

## 3. 참고

본 문서는 다음의 문서들을 참고하였습니다.

1. [Intel - What Is a GPU?](https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html)
2. [NVIDIA - What’s the Difference Between a CPU and a GPU?](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/)
3. [NVIDIA - What is CUDA?](https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/)

문서의 내용을 읽기 전에 가볍게 다음의 동영상을 보고 와주시면 감사드리겠습니다.

1. [개발자 라라 - NVIDIA의 과학시간 - GPU와 CPU의 차이](https://youtu.be/1BAZf3PsjWA)
2. [개발자 라라 - CPU와 GPU의 차이점](https://youtu.be/taMH5Dickv4)

3. [ICT이노베이션스퀘어 - 21년에 대체 뭘 알아야 AI 인재가 될 수 있을까?](https://youtu.be/XMksfH-HO84)
